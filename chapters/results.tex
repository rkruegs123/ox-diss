\chapter[Results]{Results} \label{ch:results}

% Here we present the results of our primary and alternative optimization strategies.
Here we present the results of our optimization strategy.
Before reporting on the performance of our strategy, we first conduct preliminary analyses to refine our method.
% After finalizing these refinements, we report on the performance of this strategy.
All random circuits are generated using the \codeword{CNOT_HAD_PHASE_circuit} method in PyZX which constructs a circuit consisting of CNOT, HAD, and phase gates.
Default parameters are used for the probability of each gate type.


% \section{Primary Strategy}

\section{Refinements}

General opportunities for refinement are the following:
\begin{itemize}
\item
  Optimization function
\item
  Probability of applying Equation \ref{eq:gen-io-lc} vs. Equation \ref{eq:gen-io-pivot}
\item
  Sampling of subjects (i.e., spiders or pairs of connected spiders) for congruence application
% \item
  % Probability of applying \codeword{full_reduce} throughout search, $p_{fr}$ % FIXME: Could just skip this one...
\end{itemize}
For these analyses, we only use SA as it is more computationally efficient and we expect the behavior of these refinements to generalize to GA.

We also conduct procedure-specific refinements.
We analyze how varying the number of iterations or mutants and generations affects optimization using SA and GA, respectively.

\subsection*{Optimization Function}

First, we test if any property of a ZX-diagram could serve as a reliable proxy for the complexity of its associated circuit.
To do so, we first generated 500 random circuits (10 qubits, 100 gates) and immediately converted them to ZX-diagrams.
Given this library of ZX-diagrams, we then measured the Pearson correlation coefficient between the complexity of the extracted circuit and each ZX-diagrammatic property discussed in Section \ref{sec:obj-funcs}.
The following table summarizes these correlations:
\begin{center}
  % \begin{table*}[h!]
  % \begin{tabular}[]{@{}lcc@{}}
\begin{tabular}[]{@{}l>{\centering\arraybackslash}p{1.5cm}>{\centering\arraybackslash}p{2cm}@{}}
\toprule
                    & $r$ & p-value \\ \midrule
\# Edges  & 0.097        & 0.029            \\
Centrality & 0.090        & 0.045            \\
Density    & -0.096       & 0.032            \\ \bottomrule
\end{tabular}
% \caption{\label{tab:obj-pearson}Correlations between various ZX-diagrammatic properties and the complexity of the extracted circuit for 500 randomly generated ZX-diagrams. Pearson's correlation coefficient is denoted $r$ and the 2-tailed p-value is provided. The ZX-diagrams were generated by converting 500 random circuits with 10 qubits and 100 gates to ZX-diagrams.}
% Table \ref{tab:obj-pearson} summarizes these correlations.
% \end{table*}
\end{center}
Pearson's correlation coefficient is denoted $r$ and the 2-tailed p-value is provided.
From these data, it is clear that no identified property of a ZX-diagram can serve as a reliable proxy for the complexity of its associated circuit.
Therefore, the default scoring method discussed in Section \ref{sec:strategy} that relies on extraction is used for the remainder of our analyses.



\begin{figure}[t]
\centering
\includegraphics[width=13cm]{img/cong-sampling-ex.png}
\caption{
  A representative comparison of congruence sampling methods for a 5 qubit, 50 gate circuit.
  All three sampling methods that include both LC and pivoting achieve the best simplification in the alotted number of steps.
  When using only local complementation (i.e., Equation \ref{eq:gen-io-lc}), the same best-case complexity is achieved over the 10 trials but the average complexity is higher.
  Alternatively, using only pivoting does not achieve the same reduced circuit.
}
\label{fig:cong-sampling}
\end{figure}

\subsection*{Congruence Sampling}

By default, we apply Equations \ref{eq:gen-io-lc} and \ref{eq:gen-io-pivot} with equal probability ($p_{LC} = p_{pivot} = 0.5$).
However, it may be the case that one congruence should be chosen more frequently than the other.
To evaluate this, we generated 30 random circuits (5 qubits, 50 gates) and repeated search with a range of $(p_{LC}, p_{pivot})$ pairs.
For a given circuit, search was performed 10 times for each pair and the complexities of the optimized circuits were plotted according to congruence sampling probabilities.
In all cases, the sampling methods that include both LC and pivoting yielded the lowest average complexity across the 10 trials as well as the least complex circuit overall.
% In some cases, other sampling methods matched, but never outperformed this method in either metric.
There were no significant differences between the three combined sampling methods (i.e., 50/50, 25/75, and 75/25), and the LC- ($p_{LC} = 1.0$, $p_{pivot} = 0.0$) or pivot-only ($p_{LC} = 0.0$, $p_{pivot} = 1.0$) approaches sometimes matched, but never outperformed these combined methods.
% Most notably, the least cusing only local complementation (i.e., $p_{LC} = 1.0$, $p_{pivot} = 0.0$) produced a circuit that matched the
Most notably, the least complex circuit identified using LC-only matched the minimum complexity 73.3\% of the time while that identified using pivot-only was more complex than the best-case 86.7\% of the time.
% Most notably, the least complex circuit identified using only local complementation (i.e., $p_{LC} = 1.0$, $p_{pivot} = 0.0$) matched the minimum complexity found via 50/50 sampling FIXME\% of the time and was less complex than that found using only pivoting FIXME\% of the time (and otherwise no more complex).
% Most notably, the minimum-complexity circuit identified using LC-only (i.e., $p_{LC} = 1.0$, $p_{pivot} = 0.0$) matched that found via 50/50 sampling
% method most commonly matched the default and almost always outperformed the pivot-only method.
% LC-only (i.e., $p_{LC} = 1.0$, $p_{pivot} = 0.0$) and
A representative comparison for one random circuit is shown in Figure \ref{fig:cong-sampling}.

The observation that LC-only typically outperforms pivot-only is intuitive as one pivot is equivalent to three local complementations and therefore LC-only enables a more fine-grained search.
While LC-only likely converges to the combined sampling methods in the limit, we retain pivoting in the action set as it appears to require a fewer number of iterations at no cost.
% However, since LC-only always matches and never outperforms the equal sampling of either congruences,
In the remainder of our analyses, the default uniform sampling of Equations \ref{eq:gen-io-lc} and \ref{eq:gen-io-pivot} (i.e., $p_{LC} = p_{pivot} = 0.5$) is used.


\begin{figure}[t]
\centering
\includegraphics[width=13cm]{img/subj-sampling-ex.png}
\caption{
  A representative example of optimization of a 5 qubit, 50 gate circuit with different metrics of sampling spiders for application of Equation \ref{eq:gen-io-lc}.
  Optimization was performed 10 times for each sampling method using SA with $p_{LC} = 1.0$ and $p_{pivot} = 0.0$.
  No significant differences are observed in performance across the different weightings.
}
\label{fig:subj-sampling}
\end{figure}


\subsection*{Congruence Subject Sampling}

Similar to the probabilistic sampling of congruences to apply throughout search, we can experiment with methods of sampling subjects (i.e., spiders or pairs of connected spiders) for congruence application.
By default, we sample from the set of all eligible subjects uniformly.
However, we could alternatively weight this sampling in a way that improves search.
Candidate metrics for Equations \ref{eq:gen-io-lc} and \ref{eq:gen-io-pivot} are discussed in Section \ref{sec:strategy}.

To test these alternative weightings, we employ a similar approach as for congruence sampling.
First, we restrict the action space to that congruence for which we are testing various weightings to isolate its effect.
For example, if we are testing various weighting metrics to select a spider for application of Equation \ref{eq:gen-io-lc}, we set $p_{LC} = 1.0$ and $p_{pivot} = 0.0$.
We then proceed as before, evaluating the performance of SA on random circuits across 10 trials for each candidate weighting.
We evaluate 20 random circuits (5 qubits, 50 gates) for each set of sampling procedures.

In both cases, no sampling method demonstrated consistent improvement over any other across the 20 trials.
One representative example of this comparison for sampling spiders for Equation \ref{eq:gen-io-lc} is shown in Figure \ref{fig:subj-sampling}.
Similar results were observed for sampling pairs of connected spiders for Equation \ref{eq:gen-io-pivot}.
So, for the remainder of our analyses, we sample subjects for congruence application uniformly.

\begin{figure}[t]
\centering
\includegraphics[width=13cm]{img/iter-likelihood.png}
\caption{
  The likelihood of obtaining a ZX-diagram with a simpler extracted circuit after a given iteration in SA.
  For example, after 2000 steps, there is a 20\% chance of obtaining a ZX-diagram corresponding to an even simpler circuit as search progresses.
  These data were obtained using circuits with 4-10 qubits and 10-20 gates per qubit and do not necessarily generalize to larger circuits.
}
\label{fig:iter-likelihood}
\end{figure}

\subsection*{Number of SA Iterations}

The maximum number of SA steps $k_{max}$ should be high enough to permit the bulk of optimization while low enough to be computational feasible.
We determine the optimal $k_{max}$ by optimizing a set of random circuits and computing the probability that SA uncovers a complexity reduction after fixed intervals.
First, we generated a set of 36 random circuits with 4-10 qubits (intervals of 2) and 10-20 gates per qubit (intervals of 5).
For each circuit, we obtained a simplified ZX-diagram via \codeword{teleport_reduce} + \codeword{basic_optimization}.
We then optimized each simplified ZX-diagram using SA with $k_{max} = 5000$ and recorded the complexity of the best circuit every 250 steps.
Lastly, we computed the probability that a ZX-diagram whose extracted circuit is less complex would be found as search progressed for each 250-step interval.
% Lastly, we computed the probability that a less-complex circuit would be found as search progressed for each 250-step interval.
% We repeated this entire analysis twice, once for each method of obtaining a simplified ZX-diagram from a circuit (see Figure \ref{fig:primary}).

The results of this analysis are shown in Figure \ref{fig:iter-likelihood}.
We see that most improvement occurs in the beginning of search and that the chance of finding a simpler circuit after 2500 steps is less than 10\%.
For this reason, we fix $k_{max} = 2500$ for the remainder of our analyses unless otherwise noted.


\begin{figure}
\centering
\begin{subfigure}[t]{0.47\textwidth}
  \centering
  \includegraphics[width=\linewidth]{img/ga-likelihood.png}
  \caption{The likelihood of obtaining a simpler circuit after a given generation.
  As in Figure \ref{fig:iter-likelihood}, these data were obtained using circuits with 4-10 qubits and 10-20 gates per qubit.}
  \label{fig:ga-likelihood}
\end{subfigure}
\hfill
\begin{subfigure}[t]{0.47\textwidth}
  \centering
  \includegraphics[width=\linewidth]{img/7qb}
  \caption{
    The reduction in complexities over time for 10 random 7 qubit, 100 gate circuits.
    Reduction in complexity is measured with respect to the simplified ZX-diagram rather than the original circuit.
  }
  \label{fig:7qb}
\end{subfigure}
\caption{
  GA parameter tuning
}
\label{fig:ga-params}
\end{figure}


\iffalse
\begin{figure}[t]
\centering
\includegraphics[width=13cm]{img/ga-likelihood.png}
\caption{
  The likelihood of obtaining a ZX-diagram corresponding to a simpler circuit after a given generation in GA.
  As in Figure \ref{fig:iter-likelihood}, these data were obtained using circuits with 4-10 qubits and 10-20 gates per qubit.
}
\label{fig:ga-likelihood}
\end{figure}
\fi


\subsection*{GA Parameters}

Similarly, when searching this space with GA, we want to evolve a large enough population for sufficiently many generations while incurring minimal computational cost.
To determine the appropriate population size and number of generations, we employ a similar approach as for determining $k_{max}$.
First, we generated a set of 36 simplified ZX-diagrams in the same fashion.
We then evolved each ZX-diagram for 100 generations with a population of 10, 20, or 40 mutants.
Lastly, for each population size, we computed the probability that a ZX-diagram corresponding to a simpler circuit (via extraction) would be found as search progressed for each 2-generation interval.
These probabilities for each population size are shown in Figure \ref{fig:ga-likelihood}.
Interestingly, all three population sizes exhibit similar behavior.
% Additionally, almost 50\% of all evolutions either perform all optimization in the 0th generation or provide no improvement.

We also sought to understand both the rate of reduction (with respect to the simplified ZX-diagram) over time and differences in total reduction between population sizes.
We plotted the complexity reduction over time for 10 random circuits with 7 qubits and 100 gates for each population size.
% We also generated 10 random circuits with 7 qubits and 100 gates and plotted the complexity reduction
% We also plot the complexity reduction (with respect to the simplified ZX-diagram) over time for each circuit both to evaluate the rate of reduction and to identify differences in total reduction between population sizes.
These reductions (one line per circuit for each population size) are shown in Figure \ref{fig:7qb}.
% note that there is particularly high variance in performance as the circuits have a variable number of qubits.
It is immediately clear that most optimization occurs in the first few generations.
Additionally, there is no reliable benefit provided by a larger population size.
We fix $n_{mutants} = 20$ and $n_{gens} = 40$ for the remainder of our analyses unless otherwise stated.


\begin{table}[t]
  \centering
\begin{tabular}{@{}ccccccc@{}}
\toprule
\multirow{3}{*}{\textbf{Qubits}}           & \multicolumn{6}{c}{\textbf{Complexity Reduction (\%)}}                                                      \\ \cmidrule(l){2-7}
                                           & \multirow{2}{*}{TR} & \multirow{2}{*}{FR} & \multicolumn{2}{c}{SA} & \multicolumn{2}{c}{GA} \\ \cmidrule(l){4-7}
                                           &                     &                     & TR seed    & FR seed   & TR seed    & FR seed   \\ \midrule
4                                          & 32.0                & 40.1                & 57.8       & 57.3      & 37.0       & 39.3      \\
6                                          & 10.3                & 9.4                 & 33.0       & 31.4      & 6.2        & 5.8       \\
8                                          & 2.1                 & -27.8               & 5.1        & 4.4       & -22.9      & -19.7     \\
10                                         & 5.1                 & -40.3               & -15.5      & -17.2     & -44.1      & -39.6     \\
12                                         & 1.2                 & -65.0               & -32.6      & -32.3     & -60.8      & -65.8     \\
14                                         & 1.4                 & -77.6               & -47.4      & -48.2     & -78.3      & -76.8     \\ \midrule
\multicolumn{1}{l}{\textbf{Avg. Time (s)}} & 0.03                & 0.04                & 123.1      & 122.4     & 35.8       & 33.4      \\ \bottomrule
\end{tabular}
\caption{\label{tab:init-results}
  A comparison of our optimization strategy with off-the-shelf PyZX methods using default parameters for varying circuit sizes (15 gates per qubit).
  Complexity reduction is measured with respect to the original circuit.
  TR and FR denote the two standard optimization pipelines in PyZX based on {\color{gray}\texttt{teleport\_reduce}} and {\color{gray}\texttt{full\_reduce}}, respectively.
  TR seed and FR seed denote the two methods of obtaining an initial simplified ZX-diagram (see Figure \ref{fig:primary}).
}
\end{table}





\begin{table}[t]
  % \small
  % \footnotesize
  \scriptsize
  \centering
  \subfloat[15 gates per qubit]{
  \begin{tabular}{@{}ccccccc@{}}
  \toprule
  \multirow{2}{*}{\textbf{Qubits}} & \multicolumn{6}{c}{\textbf{Complexity Reduction (\%)}} \\ \cmidrule(l){2-7}
                                   & TR     & FR    & SA    & GA    & qiskit    & tket    \\ \midrule
  4                                & 32.0      & 40.1     & 58.6     & 45.1     & 23.9         & 34.2         \\
  6                                & 10.3      & 9.4     & 34.2     & 7.4     & 13.9         & 14.5         \\
  8                                & 2.1      & -27.8     & 7.6     & -22.9     & 8.6         & 4.2         \\
  10                               & 5.1      & -40.3     & -11.9     & -43.3     & 8.2         & 1.9         \\
  12                               & 1.2      & -65.0     & -30.1     & -66.0    & 5.9         & -2.1         \\
  14                               & 1.4      & -77.6     & -45.0     & -79.6     & 5.1         & -3.4         \\
  % \midrule
  % \textbf{\begin{tabular}[c]{@{}c@{}}Avg. \\ Time (s)\end{tabular}}           & 0.03      & 0.04     & 332.4     & 53.4     & 0.2         & 0.02         \\
  \bottomrule
  \end{tabular}}
  \quad
  \subfloat[40 gates per qubit]{
  \begin{tabular}{@{}ccccccc@{}}
  \toprule
  \multirow{2}{*}{\textbf{Qubits}} & \multicolumn{6}{c}{\textbf{Complexity Reduction (\%)}} \\ \cmidrule(l){2-7}
                                   & TR     & FR    & SA    & GA    & qiskit    & tket    \\ \midrule
  4                                & 41.1      & 61.3     & 70.5     & 63.0     & 21.8         & 36.5         \\
  6                                & 20.2      & 38.4     & 50.1     & 38.3     & 13.4         & 15.7         \\
  8                                & 12.1      & 11.0     & 26.3     & 10.9     & 10.7         & 8.9         \\
  10                               & 9.5      & -6.8     & 10.4     & -6.7     & 9.3         & 5.9         \\
  12                               & 8.0      & -28.5     & -10.6     & -27.0     & 7.8         & 3.2         \\
  14                               & 4.2      & -46.3     & -29.5     & -45.6     & 6.1         & 0.07         \\
  % \midrule
  % \textbf{\begin{tabular}[c]{@{}c@{}}Avg. \\ Time (s)\end{tabular}}           & 0.1      & 0.1     & 943.9     & 140.6     & 0.3         & 0.07         \\
  \bottomrule
  \end{tabular}}
  \caption{\label{tab:compare-results}
    A comparison of our optimization strategy with off-the-shelf methods using parameters that lend to increased runtime and performance.
    The optimization procedures in both {\color{gray}\texttt{qiskit}} and {\color{gray}\texttt{tket}} execute in $<1\text{s}$.
  }
\end{table}




\section{Performance}

After refining the parameters of our method, we sought to understand our method's ability to optimize a given input circuit.
For $4, 6, \dots 14$ qubits, we optimized the simplified ZX-diagrams of 10 randomly generated circuits with 15 gates per qubit.
We recorded the average complexity reduction with respect to the original circuit (rather than the simplified ZX-diagram) as well as the execution time.
We conducted this analysis for six optimization methods -- both off-the-shelf optimization pipelines in PyZX, and all four combinations of the two search procedures and the two methods for obtaining an initial simplified ZX-diagram.
These data are shown in Table \ref{tab:init-results}.

Immediately we see that our strategy outperforms existing methods for low qubit numbers ($<10$).
For circuits with $\geq 10$ qubits, our method produces a circuit that is more complex than the original circuit.
For these larger circuits, our method performs worse than the \codeword{teleport_reduce} pipeline, which guarantees to not introduce complexity given its lack of circuit extraction, but introduces less additional complexity than the \codeword{full_reduce} pipeline.
Furthermore, neither method of obtaining a simplified ZX-diagram to seed search appears to provide benefit over the other.
However, SA consistently outperforms GA.
% Lastly, not pictured in Table \ref{tab:init-results} is that all complexity reduction obtained via SA and GA was driven by a reduction in the number of 2-qubit gates;
% in all applications of our strategy, the T-count remained unchanged from the simplified ZX-diagram and the overall number of single-qubit gates never decreased.
% FIXME: Get some numbers for this?




\begin{table}[t]
  \footnotesize
  \centering
\begin{tabular}{@{}ccccccccccccc@{}}
\toprule
 &
   &
   &
   &
  \multicolumn{4}{c}{\textbf{Reduction (\%)}} &
  \multicolumn{1}{l}{} &
  \multicolumn{4}{c}{\textbf{2-qubit Count}} \\ \cmidrule(lr){5-8} \cmidrule(l){10-13}
\textbf{Circuit} &
  \textbf{n} &
  \textbf{Gates} &
  % \textbf{\begin{tabular}[c]{@{}c@{}}2-qubit\\ Count\end{tabular}} &
  \textbf{2-qb} &
PyZX &
  SA &
  qiskit &
  tket &
   &
  PyZX &
  SA &
  qiskit &
  tket \\ \midrule
barenco-tof-3                & 5  & 58   & 24  & 0.7  & 29.9  & 0.7  & -6.6  &  & 24  & 17  & 24  & 24  \\
barenco-tof-4                & 7  & 114  & 48  & 5.5  & 32.1  & 0.9  & -4.9  &  & 47  & 33  & 48  & 48  \\
barenco-tof-5                & 9  & 170  & 72  & 1.0  & 32.9  & 1.0  & -4.4  &  & 72  & 49  & 72  & 72  \\
$\text{gf}(2^4)\text{-mult}$ & 12 & 243  & 99  & 3.1  & -96.6 & 2.6  & -1.7  &  & 99  & 215 & 99  & 99  \\
grover-5                     & 9  & 831  & 288 & 4.3  & 19.5  & 1.8  & -19.0 &  & 288 & 248 & 288 & 288 \\
$\text{hwb}_6$               & 7  & 259  & 116 & 5.3  & 5.7   & 0.8  & -8.3  &  & 111 & 112 & 116 & 111 \\
$\text{mod5}_4$              & 5  & 63   & 28  & 14.3 & 52.4  & 1.0  & -5.4  &  & 26  & 14  & 28  & 28  \\
mod-mult-55                  & 9  & 119  & 48  & 2.9  & -16.0 & 0.4  & -19.6 &  & 48  & 59  & 48  & 48  \\
mod-red-21                   & 11 & 278  & 105 & 2.7  & 7.3   & 1.4  & -22.5 &  & 105 & 103 & 105 & 105 \\
$\text{nth-prime}_6$         & 9  & 1241 & 502 & 5.8  & 23.4  & 2.5  & -6.1  &  & 502 & 401 & 498 & 493 \\
$\text{rc-adder}_6$          & 14 & 200  & 93  & 13.2 & 31.4  & 10.1 & -3.5  &  & 81  & 64  & 83  & 81  \\
$\text{tof}_3$               & 5  & 45   & 18  & 0.5  & 22.2  & 0.5  & -9.2  &  & 18  & 14  & 18  & 18  \\
$\text{tof}_4$               & 7  & 75   & 30  & 0.6  & 26.7  & 0.6  & -35.4 &  & 30  & 22  & 30  & 30  \\
$\text{tof}_5$               & 9  & 105  & 42  & 0.6  & 22.2  & 0.6  & -8.9  &  & 42  & 33  & 42  & 42  \\
$\text{vbe-adder}_3$         & 10 & 150  & 70  & 16.7 & 44.7  & 15.9 & 12.4  &  & 58  & 39  & 58  & 58  \\ \bottomrule
\end{tabular}
\caption{\label{tab:bench}
  An evaluation of our method on the benchmark circuits from \cite{kissinger2019reducing} with at most 14 qubits.
  The number of qubits of the input circuit is denoted $n$.
  We abbreviate the number of 2-qubit gates in the input circuit as 2-qb.
  The PyZX column corresponds to whichever of PyZX's two standard optimization pipelines (i.e., {\color{gray}\texttt{full\_reduce}} or {\color{gray}\texttt{teleport\_reduce}} followed by circuit-level optimizations) resulted in the best reduction for a given circuit.
}
\end{table}








Not shown in Table \ref{tab:init-results} is that in all optimization conducted via our method, the overall number of single-qubit gates never decreased from this initial simplified ZX-diagram.
Notably, however, the T-count remained unchanged.
This means that all reduction in complexity achieved via our method is a consequence of reducing the number of 2-qubit gates.
We expand on this in our analysis on (non-random) benchmark circuits.

We then sought to both stress the performance of our method and place it in the broader landscape of circuit optimization techniques.
We conducted the same analysis with the following changes:
\begin{enumerate}
\item
  We only used \codeword{teleport_reduce} + \codeword{basic_optimization} to obtain a simplified ZX-diagram as there are no significant performance differences between the two methods.
\item
  We adjusted search parameters in a way that increases execution time but may lend to better performance.
  For SA, we used three random restarts rather than a single instantiation.
  For GA, we increased $n_{gens}$ to 75.
\item
  We included the standard optimization procedures in IBM's \codeword{qiskit}~\cite{Qiskit} and Cambridge Quantum Computing's \codeword{tket}~\cite{sivarajah2020t} libraries as baselines.
\end{enumerate}
We repeated this analysis on circuits with both 15 and 40 gates per qubit.

The results of this analysis are shown in Table \ref{tab:compare-results}.
First, we observe minor increases in the performance of annealing from the two additional random restarts.
Similarly, the additional generations in the evolutionary approach result in substantial improvements for the 4-qubit circuits but minor differences at other sizes;
SA continues to consistently outperform GA.
Secondly, while we again observe a decrease in performance with the number of qubits, our method appears to scale with the number of total gates in the input circuit.
For circuits with 40 gates per qubit, annealing yields a 10\% reduction in complexity compared to the increase in complexity at 15 gates per qubit.
This result aligns with the general trend that the circuits with 40 gates per qubit appear to be more reducible than those with fewer gates.
Lastly, our method outperforms both additional off-the-shelf methods at low numbers of qubits.

Lastly, we sought to evaluate our method on a non-random class of circuits.
We tested our approach alongside off-the-shelf methods on all benchmark circuits from \cite{kissinger2019reducing} with at most 14 qubits.
We only used SA given its continued benefit over GA and conducted three random initializations for each circuit.

Table \ref{tab:bench} provides a summary of these analyses.
Excitingly, our method outperforms existing libraries in 86.7\% of cases (all but two).
Most notably, our method performs far better on benchmark circuits with $>8$ qubits than on randomly generated circuits of similar sizes.
For example, our method reduces a 14-qubit circuit (i.e., $\text{rc-adder}_6$) by 31.4\%.
Furthermore, in all cases that annealing reduced circuit complexity, we observe significant reductions in 2-qubit count yet the number of single-qubit gates is never lower than the circuit extracted from the simplified ZX-diagram used to seed search (not shown).
This provides further evidence that our simplification procedure is only effective in reducing the 2-qubit count and at best does not increase the number of single-qubit gates.
We leave proving such a property to future work.


% Lastly, baselines under a threshold qubit count. Side-by-side table and example figure?
